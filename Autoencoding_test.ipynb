{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from templates import *\n",
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 160.69 M\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "conf = ffhq256_autoenc()\n",
    "# print(conf.name)\n",
    "model = LitModel(conf)\n",
    "state = torch.load(f'ckpt/ffhq_256/last.ckpt', map_location='cpu')\n",
    "model.load_state_dict(state['state_dict'], strict=False)\n",
    "model.ema_model.eval()\n",
    "model.ema_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_root='/home/v-houxingren/cjh/dataset/CelebA-HQ/style/images/'\n",
    "data_root = 'F://Dataset/ffhq/cmp_ori'\n",
    "xt_root = 'H://pku/coding_test/coding_comparison/For_diffae/xt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "[WindowsPath('169.jpg'), WindowsPath('21205.jpg'), WindowsPath('21334.jpg'), WindowsPath('46293.jpg'), WindowsPath('46690.jpg'), WindowsPath('46725.jpg'), WindowsPath('46954.jpg'), WindowsPath('46988.jpg'), WindowsPath('169.jpg'), WindowsPath('21205.jpg'), WindowsPath('21334.jpg'), WindowsPath('46293.jpg'), WindowsPath('46690.jpg'), WindowsPath('46725.jpg'), WindowsPath('46954.jpg'), WindowsPath('46988.jpg')]\n"
     ]
    }
   ],
   "source": [
    "data = ImageDataset(data_root, image_size=conf.img_size, exts=['jpg', 'JPG', 'png'], do_augment=False)\n",
    "print(len(data.paths))\n",
    "print((data.paths))\n",
    "dataloader = DataLoader(data,\n",
    "                       batch_size = 1,\n",
    "                       num_workers = 1,\n",
    "                       shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "16"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)\n",
    "# print(data[15]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\cjh09\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\cjh09\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"C:\\Users\\cjh09\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"C:\\Users\\cjh09\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"C:\\Users\\cjh09\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 85, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'pathlib.WindowsPath'>\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [48]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i,data_i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i\u001B[38;5;241m>\u001B[39m\u001B[38;5;241m10\u001B[39m:\n\u001B[0;32m      3\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:435\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    433\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    434\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 435\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    436\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    438\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    439\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1085\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1083\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1084\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[1;32m-> 1085\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1111\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1109\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[0;32m   1110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[1;32m-> 1111\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1112\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\_utils.py:428\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    424\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexc_type, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    425\u001B[0m     \u001B[38;5;66;03m# Some exceptions have first argument as non-str but explicitly\u001B[39;00m\n\u001B[0;32m    426\u001B[0m     \u001B[38;5;66;03m# have message field\u001B[39;00m\n\u001B[0;32m    427\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexc_type(message\u001B[38;5;241m=\u001B[39mmsg)\n\u001B[1;32m--> 428\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexc_type(msg)\n",
      "\u001B[1;31mTypeError\u001B[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\cjh09\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\cjh09\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"C:\\Users\\cjh09\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in default_collate\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"C:\\Users\\cjh09\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 73, in <dictcomp>\n    return {key: default_collate([d[key] for d in batch]) for key in elem}\n  File \"C:\\Users\\cjh09\\Anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 85, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'pathlib.WindowsPath'>\n"
     ]
    }
   ],
   "source": [
    "for i,data_i in enumerate(dataloader):\n",
    "    if i>10:\n",
    "        break\n",
    "    imgs = data_i['img']\n",
    "#     print(imgs.shape)\n",
    "    cond = model.encode(imgs.to(device)) \n",
    "    xT = model.encode_stochastic(imgs.to(device), cond, T=250)\n",
    "    xT = xT.cpu().detach().numpy()\n",
    "    print(np.min(xT),np.max(xT))\n",
    "    xT = xT * 2\n",
    "    xT = np.round(xT).astype(int)\n",
    "    xT = xT + 24\n",
    "    print(np.min(xT),np.max(xT))\n",
    "    xT = xT.astype(np.uint8)\n",
    "    xT = np.transpose(xT,(0,2,3,1))\n",
    "    name = os.path.join(xt_root,data_i['path'].split('.')[0]+'.png')\n",
    "    imageio.imsave(name,xT[0])\n",
    "\n",
    "    # xenc.append(xT.cpu().detach().numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(xenc)):\n",
    "#     if i == 0:\n",
    "#         codes = xenc[i]\n",
    "#     else:\n",
    "#         codes = np.concatenate((codes,xenc[i]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = codes / 0.5\n",
    "codes = np.round(codes).astype(int)\n",
    "# codes = codes + 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = codes + 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = codes.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 256, 256, 3)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = np.transpose(codes,(0,2,3,1))\n",
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"test/xt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(codes.shape[0]):\n",
    "    name = os.path.join(save_path,str(i)+'.png')\n",
    "    imageio.imsave(name,codes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(codes.flatten(), 100, density=True)\n",
    "plt.xlabel('xT')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of xT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004473167"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0402167"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_path = 'test/xt_vvc_36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xt(i):\n",
    "    xtp=os.path.join(xt_path,str(i)+'.jpg')\n",
    "    xtp = imageio.imread(xtp)\n",
    "    xtp = np.asarray(xtp)\n",
    "    print(xtp.shape,np.min(xtp),np.max(xtp))\n",
    "    xtp = np.transpose(xtp,(2,0,1))\n",
    "    xtp = np.expand_dims(xtp,axis=0)\n",
    "#     xt = (xtp-24)*2\n",
    "#     print(xt.shape,xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3) 82 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18831/1179264662.py:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  xtp = imageio.imread(xtp)\n"
     ]
    }
   ],
   "source": [
    "get_xt(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[138 149 127]\n",
      "  [149 149 138]\n",
      "  [149 138 138]\n",
      "  ...\n",
      "  [138 149 138]\n",
      "  [138 149 127]\n",
      "  [149 149 149]]\n",
      "\n",
      " [[149 138 149]\n",
      "  [138 149 149]\n",
      "  [138 138 138]\n",
      "  ...\n",
      "  [138 138 138]\n",
      "  [138 138 149]\n",
      "  [127 127 149]]\n",
      "\n",
      " [[138 138 149]\n",
      "  [138 138 138]\n",
      "  [138 138 138]\n",
      "  ...\n",
      "  [138 138 138]\n",
      "  [138 138 138]\n",
      "  [138 127 138]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[181 149 127]\n",
      "  [170 159 159]\n",
      "  [117 191 117]\n",
      "  ...\n",
      "  [138 138 138]\n",
      "  [149 149 138]\n",
      "  [159 149 149]]\n",
      "\n",
      " [[127 127 117]\n",
      "  [106 149 117]\n",
      "  [127 138 149]\n",
      "  ...\n",
      "  [127 127 127]\n",
      "  [138 138 127]\n",
      "  [149 138 149]]\n",
      "\n",
      " [[ 85 138 149]\n",
      "  [149 106 159]\n",
      "  [117 170 149]\n",
      "  ...\n",
      "  [117 117 127]\n",
      "  [138 138 138]\n",
      "  [127 138 149]]]\n",
      "(256, 256, 3) 0 255\n"
     ]
    }
   ],
   "source": [
    "xt1 =Image.open(\"test/xt/1.png\")\n",
    "xt1 = np.asarray(xt1)\n",
    "print(xt1)\n",
    "print(xt1.shape,np.min(xt1),np.max(xt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data_i in enumerate(dataloader):\n",
    "#     if i>10:\n",
    "#         break\n",
    "    imgs = data_i['img']\n",
    "#     print(imgs.shape)\n",
    "    cond = model.encode(imgs.to(device)) \n",
    "    xtp=os.path.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "ldm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}